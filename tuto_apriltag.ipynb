{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The AprilTag system: 6DoF vision with monocular cameras\n",
    "\n",
    "\n",
    "The library Apriltag allows us to detect markers in images, and to compute the relative pose between the camera coordinate frame and the tag.\n",
    "\n",
    "We will need Apriltag, OpenCV-python, and some NumPy operations to proceed. Install them with\n",
    "\n",
    "```terminal\n",
    "python -m pip install apriltag\n",
    "python -m pip install opencv-python\n",
    "```\n",
    "Then import them to your python project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apriltag\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting apriltags in images\n",
    "\n",
    "First we need to read an image into memory, and store it as greyscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./data/skew.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "cv2.imshow(\"Image view\", image)\n",
    "cv2.waitKey(1000) # waits until a key is pressed\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need an apriltag detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = apriltag.Detector()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now we can process the image, and see what comes out of the Apriltag detector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = detector.detect(image)\n",
    "\n",
    "print('detections = \\n', detections)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we've processed an image, and discovered one Tag, labelled with the ID=5.\n",
    "\n",
    "We have some more information regarding this detection, which we can access easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for detection in detections:  \n",
    "\n",
    "    print('tag #             ', detection.tag_id)\n",
    "    print('detection hamming ', detection.hamming)\n",
    "    print('detection goodness', detection.goodness)\n",
    "    print('decision margin   ', detection.decision_margin)\n",
    "    print('tag center        ', detection.center)\n",
    "    print('homography\\n',       detection.homography)\n",
    "    print('tag corners\\n',      detection.corners)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These fields are documented in Apriltag as follows\n",
    "\n",
    "    # The decoded ID of the tag\n",
    "    tag_id\n",
    "\n",
    "    # How many error bits were corrected? Note: accepting large numbers of\n",
    "    # corrected errors leads to greatly increased false positive rates.\n",
    "    # NOTE: As of this implementation, the detector cannot detect tags with\n",
    "    # a hamming distance greater than 2.\n",
    "    hamming\n",
    "\n",
    "    # A measure of the quality of tag localization: measures the\n",
    "    # average contrast of the pixels around the border of the\n",
    "    # tag. refine_pose must be enabled, or this field will be zero.\n",
    "    goodness\n",
    "\n",
    "    # A measure of the quality of the binary decoding process: the\n",
    "    # average difference between the intensity of a data bit versus\n",
    "    # the decision threshold. Higher numbers roughly indicate better\n",
    "    # decodes. This is a reasonable measure of detection accuracy\n",
    "    # only for very small tags-- not effective for larger tags (where\n",
    "    # we could have sampled anywhere within a bit cell and still\n",
    "    # gotten a good detection.)\n",
    "    decision_margin\n",
    "\n",
    "    # The 3x3 homography matrix describing the projection from an\n",
    "    # \"ideal\" tag (with corners at (-1,-1), (1,-1), (1,1), and (-1,\n",
    "    # 1)) to pixels in the image. This matrix will be freed by\n",
    "    # apriltag_detection_destroy.\n",
    "    homography\n",
    "\n",
    "    # The center of the detection in image pixel coordinates.\n",
    "    center\n",
    "\n",
    "    # The corners of the tag in image pixel coordinates. These always\n",
    "    # wrap counter-clock wise around the tag.\n",
    "    corners"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing camera-to-tag relative pose\n",
    "\n",
    "Camera-to-tag transforms can be obtained from the detected corners if we know\n",
    "  - the geometry of the tags\n",
    "  - the geometry of the camera (intrinsic and distortion parameters)\n",
    "\n",
    "So let us define these parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag geometry\n",
    "tag_size    = 0.2\n",
    "tag_corners = tag_size / 2 * np.array([[-1,1,0],[1,1,0],[1,-1,0],[-1,-1,0]])\n",
    "\n",
    "# Camera calibration \n",
    "K = np.array([  [   320,    0.0,    320  ], \n",
    "                [   0.0,    320,    240  ], \n",
    "                [   0.0,    0.0,    1.0  ]])  \n",
    "# warning: these params do not corresopnd to the ones of the camera used to take the image skew.jpeg\n",
    "\n",
    "distortion_model = np.array([])  # we assume rectified images, therefore with no distortion\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here there are two ways of computing the relative pose between the camera and the tag.\n",
    "\n",
    "- One method uses the **homography** provided by the detector to extract translation `T` and rotation `R`. This method is unstable and we do not recommend it.\n",
    "\n",
    "- The other method uses the **PnP algorithm**. Given the four corners of the tag in tag reference (which are known), the  same corners projected in the image, obtained by the Apriltag detector, and the camera calibration parameters, the PnP algorithm computes the transformation (`T`,`R`) between camera and tag. \n",
    "\n",
    "We use OpenCV for this, and recover a translation vector and a rotation vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_, rotation_vector, translation_vector) = cv2.solvePnP(tag_corners, detection.corners, K, distortion_model, flags = cv2.SOLVEPNP_IPPE_SQUARE)\n",
    "\n",
    "T = translation_vector\n",
    "w = rotation_vector\n",
    "\n",
    "print('T = \\n', T)\n",
    "print('w = \\n', w)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See that although `T` and `w` are vectors, they come represented as 2-dimensional arrays. We can clean them up to avoid trouble down the road:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = (T.T)[0]\n",
    "w = (w.T)[0]\n",
    "\n",
    "print('T = \\n', T)\n",
    "print('w = \\n', w)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now important to know how to interpret these `T` and `R`. Are they _camera-to-tag_? Or _tag-to-camera_? Reading the doc of `cv2.computePnP()`, we see that they transform points in tag frame into points in camera frame. Let us rename the variables to account for this and be more verbose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_c_t = T\n",
    "w_c_t = w"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to obtain a rotation matrix from a rotation vector, we require the exponential in SO(3), or the Rodrigues formula. We use pinocchio for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinocchio as pin\n",
    "\n",
    "R_c_t = pin.exp(w_c_t)\n",
    "\n",
    "print('R = \\n',R_c_t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now reproject the tag corners into the image, and see if they differ much from the detections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_corners = cv2.projectPoints(tag_corners, R_c_t, T_c_t, K, distortion_model)\n",
    "projected_corners = np.reshape(projected_corners[0],[4,2])  # fix weird format from opencv\n",
    "\n",
    "print('projected corners\\n', projected_corners)\n",
    "print()\n",
    "print('detected corners\\n', detection.corners)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that they kind of match, but not really. This is because the image used was taken from the internet, and we do not have the correct camera calibration parameters.\n",
    "\n",
    "Let us then re-do the whole process with a proper image taken a the camera with known calibration parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./data/visual_odom_laas_corridor/short2/frame0000.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "cv2.imshow(\"Image view\", image)\n",
    "cv2.waitKey(10) # waits so the image can be drawn (??)\n",
    "\n",
    "# Camera calibration\n",
    "K           = np.array([[   419.53, 0.0,    427.88  ], \n",
    "                        [   0.0,    419.53, 241.32  ], \n",
    "                        [   0.0,    0.0,    1.0     ]])  \n",
    "\n",
    "detections = detector.detect(image)\n",
    "\n",
    "for detection in detections[0:2]:   # we'll show results of only 2 detections\n",
    "\n",
    "    print('Tag # ', detection.tag_id)\n",
    "\n",
    "    (_, w_c_t, T_c_t) = cv2.solvePnP(tag_corners, detection.corners, K, distortion_model, flags = cv2.SOLVEPNP_IPPE_SQUARE)\n",
    "    R_c_t = pin.exp(w_c_t)\n",
    "\n",
    "    projected_corners = cv2.projectPoints(tag_corners, R_c_t, T_c_t, K, distortion_model)\n",
    "    projected_corners = np.reshape(projected_corners[0],[4,2])  # fix weird format from opencv\n",
    "    \n",
    "    print('projected corners\\n', projected_corners)\n",
    "    print('detected corners\\n', detection.corners)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing tag detection quality\n",
    "\n",
    "The quality of a detection can be assessed with different metrics. We provide here some clues:\n",
    "\n",
    "- Use the `detection.goodness` result\n",
    "- Use the `detection.hamming` result\n",
    "- Use the `detection.decision_margin` result\n",
    "- Use the reprojection error of the corners. \n",
    "\n",
    "We do not provide further details here, but you may explore these possibilities should your SLAM algorithm show signs of fragility:\n",
    "- For the Apriltag detector metrics, see the documentation above\n",
    "- For the reprojection error, you can use the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection = detections[0]\n",
    "\n",
    "(_, w_c_t, T_c_t) = cv2.solvePnP(tag_corners, detection.corners, K, distortion_model, flags = cv2.SOLVEPNP_IPPE_SQUARE)\n",
    "R_c_t = pin.exp(w_c_t)\n",
    "\n",
    "projected_corners   = cv2.projectPoints(tag_corners, R_c_t, T_c_t, K, distortion_model)\n",
    "projected_corners   = np.reshape(projected_corners[0],[4,2])  # fix weird format from opencv\n",
    "\n",
    "reprojection_errors = projected_corners - detection.corners\n",
    "\n",
    "reprojection_error_rms = np.linalg.norm(reprojection_errors) / np.sqrt(8.0)\n",
    "\n",
    "print('reprojection errors [pix]\\n', reprojection_errors)\n",
    "print('reprojection_error_rms [pix rms]\\n', reprojection_error_rms)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's all we need to know about the `AprilTag` package to make 3D measurements of tags in the environment!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
